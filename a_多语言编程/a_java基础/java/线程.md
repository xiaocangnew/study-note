### 线程池的实现类 ThreadPoolExecutor构造函数参数
- corePoolSize ：
    核心线程数即一直保留在线程池中的线程数量，即使处于闲置状态也不会被销毁。 allowCoreThreadTimeOut为true销毁核心线程
    当提交一个任务到线程池的时候，线程池会创建一个线程来执行执行任务，如果线程数量小于corePoolSize，每次都会新建；
- maximumPoolSize：
    线程池允许创建的最大线程数；如果阻塞队列已经满了，同时已经创建的线程数小于最大线程数的话，那么会创建新的线程来处理阻塞队列中的任务；
- keepAliveTime ：
    非核心线程允许的最大闲置时间，超过这个时间就会本地销毁。
- workQueue：用来存放任务的队列。
    - SynchronousQueue：
        没有容量，是无缓冲等待队列的阻塞队列，直接将任务交给消费者线程;阻塞时直接拒绝策略(一般要求maximumPoolSizes为无界)
        拥有公平（FIFO）和非公平(LIFO)策略
    - LinkedBlockingQueue：
        这个队列是一个无界队列。如果线程池中的线程数等于corePoolSize将任务放入队列中等待，由于队列大小没有限制所以也被称为无界队列。
        当使用这个队列的时候maximumPoolSizes不生效（线程池中线程的数量不会超过corePoolSize），所以一般都会设置为0。
    - ArrayBlockingQueue：
        可以设置队列的最大容量的有界队列。当线程池中线程数大于或者等于 maximumPoolSizes 的时候，就会把任务放到这个队列中，
        当前队列中的任务大于队列的最大容量就会丢弃掉该任务交由 RejectedExecutionHandler 处理。
- 4种拒绝策略：
  1. 丢弃任务并抛异常(默认)
  2. 丢弃任务不抛异常
  3. 丢弃队列最前面的任务，重新提交
  4. 由提交任务的线程执行该任务。

- [线程池数量](https://blog.csdn.net/hzw19920329/article/details/52372348?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control)
1. poolSize < corePoolSize，则直接创建新的线程(核心线程)来执行当前提交的任务；
2. poolSize = corePoolSize，并且此时阻塞队列没有满，那么会将当前任务添加到阻塞队列中，
 如果此时存在工作线程(非核心线程)的话，那么会由工作线程来处理该阻塞队列中的任务，如果此时工作线程数量为0的话，那么会创建一个工作线程(非核心线程)出来；
3. poolSize = corePoolSize，并且此时阻塞队列已经满了，那么会直接创建新的工作线程(非核心线程)来处理阻塞队列中的任务；
4. poolSize = maximumPoolSize，并且此时阻塞队列也满了的话，那么会触发拒绝机制，
   具体决绝策略采用的是什么就要看我们创建ThreadPoolExecutor的时候传入的RejectExecutionHandler参数了；

- 线程池是如何复用线程的
1. 一个线程池中线程的数量实际上就是这个线程池中Worker的数量，如果Worker的大小超过了corePoolSize，那么任务都在阻塞队列里面了，
      Worker是Java对我们任务的一个封装类，实现了runnable接口
2. addWorker主要负责创建新的线程并执行任务; 流程是
    1. CAS更新线程池数量
    2. 加重入锁， 将worker加入到workers中去； 解锁
    3. worker.start(); worker启动后，使用while循环，重复从阻塞队列中拉取任务并执行任务的run方法；直至阻塞队列为空；
        
        
- 线程执行失败
1. 如果是Future f = poll.submit(runnable), 在future里进行catch处理就可以了。
2. 使用execute()时：
   1. 把runnable用try-catch包起来。不太好，异常处理丑陋，增加代码量。
   2. 自定义线程池，继承ThreadPoolExecutor并复写其afterExecute(Runnable r, Throwable t)方法。
   3. (默认实现打印异常)实现Thread.UncaughtExceptionHandler接口和接口中的方法uncaughtException(Thread t, Throwable e)
      并将该handler传递给线程池的参数：ThreadFactory(threadFactory.newThread(Runnable r))。
        
- 如何确定线程池中线程的个数
1.任务的性质：CPU密集型任务(cpu个数+1)
           IO密集型任务(因为不占用cpu，所以可以加大。2*cpu个数+1)
           
### 定时线程池 ScheduledThreadPoolExecutor 实现
1. schedule(Runnable command,long delay,TimeUnit unit)
  将放入的任务增加一个delay延迟字段，然后使它被取出时，等待delay这么长就行
2. 使用了一个延时队列DelayQueue，每次poll时总是把最小delay的任务取出来；
        
### 如何控制线程池线程的优先级
1. 简单的，传入任务时，同时设置该线程的优先级();
2. 使用ThreadPoolExecutor实现一个带优先级的线程池:
    使用PriorityBlockingQueue优先级队列.(PriorityBlockingQueue的坑：如果优先级相同,不能确定顺序；需要自定义一个)

###  线程池的生命周期
1. RUNNING
2. SHUTDOWN(不接收新任务，正常处理已有任务)
    调用线程池的shutdown()接口时，线程池由RUNNING -> SHUTDOWN。
3. STOP(不接收新任务，中断正在处理的任务)
    调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -> STOP。
4. tidying(所有的任务已终止，ctl记录的”任务数量”为0)
    当线程池变为TIDYING状态时，会执行钩子函数terminated()。
5. TERMINATED(线程池彻底终止)
    线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING -> TERMINATED。

### 线程池中的变量
32位AtomicInteger类型的原子变量ctl来控制线程池的状态，
高3位用于存储线程池的五种状态即runState，
低29位存储线程池中工作线程的数量即workerCount，线程池最多可以创建的工作线程的数量是2^29)-1(大约5亿)个线程。


###线程上下文
- 上下文的内容
    1.寄存器的存储内容：CPU寄存器负责存储已经、正在和将要执行的任务
    2.程序计数器存储的指令内容：程序计数器负责存储CPU正在执行的指令位置、即将执行的下一条指令的位置
- 线程上下文切换的系统开销
    1. 操作系统保存和恢复上下文
    2. 调度器进行线程调度
    3. 处理器高速缓存重新加载
    4. 可能导致整个高速缓存区被冲刷，从而带来时间开销
- 诱因：程序本身触发的自发性上下文切换、系统或虚拟机触发的非自发性上下文切换
    1. 自发性上下文切换
        sleep、wait、yield、join、park、synchronized、lock
    2. 非自发性上下文切换
        线程被分配的时间片用完、JVM垃圾回收（STW、线程暂停）、线程执行优先级


### InterruptedException
- 当阻塞方法收到中断请求的时候就会抛出InterruptedException异常
     1. wait/sleep导致的阻塞
     2. 没有抢到锁导致的阻塞
- interrupt()方法并不能立即中断线程，该方法仅仅告诉线程外部已经有中断请求，至于是否中断还取决于线程自己
     0. 线程内部有个一个boolean类型的标志，此标志意思是当前的请求是否请求中断(默认为false)
     1. 阻塞方法收到中断请求，抛出InterruptedException，同时它会将线程B的是否请求中断标志置为false
     2. 非阻塞方法收到中断请求, 不会抛出InterruptedException，静态方法它检测完以后会自动的将是否请求中断标志位置为false


### 线程间通信， 一个线程需要等待另一个线程
1. 同步阻塞的方式：
     1. 使用condition通信，await/signal方法
     2. 使用countdownLatch.
2. 异步方式
     1. 使用completableFuture

### [CompletableFuture](https://www.jianshu.com/p/b3c4dd85901e)
1. 为什么要用这个
       1. 处理非阻塞调用的传统方法是使用事件处理器，程序员为任务完成之后要出现的动作注册一个处理器。
            但是，要尝试在一组事件处理器中实现一个控制流会很困难。
       2. 利用CompletableFuture，可以指定希望做什么，以及希望以什么顺序执行这些工作。
            这些动作不会立即发生，不过重要的是将所有代码放在一起。
2. 对于阻塞或者轮询方式，依然可以通过CompletableFuture类的CompletionStage和Future接口方式支持。
       CompletionStage接口实际上提供了同步或异步运行计算的舞台，
       通过实现多个CompletionStage命令，并且将这些命令串联在一起的方式实现多个命令之间的触发。
3. 每一种方法的两种形式
       1. 同步方法由当前线程或调用线程执行
       2. 异步方法
            不带executor的异步方法使用asyncPool来执行
            另一种异步方法使用executor执行
4. 创建CompletableFuture
       1. CompletableFuture<U> supplyAsync(Supplier<U> supplier)
       2. CompletableFuture<Void> runAsync(Runnable runnable)
5. 中间组合操作
     5.1  CompletableFuture<Void> thenRun(Runnable action)               纯消费
     5.2  CompletableFuture<Void> thenAccept(Consumer<? super T> action)  纯消费
     5.3  CompletableFuture<U> thenApply(
                 Function<? super T,? extends U> fn)
     5.4 CompletableFuture<V> thenCombine(
                 CompletionStage<? extends U> other,
                 BiFunction<? super T,? super U,? extends V> fn)
     5.5 CompletableFuture<U> thenCompose(
                 Function<? super T, ? extends CompletionStage<U>> fn)


### CompletionStage
- CompletionStage定义了一组接口用于在一个阶段执行结束之后，要么继续执行下一个阶段，要么对结果进行转换产生新的结果等等，一般来说要执行下一个阶段都需要上一个阶段正常完成，当然这个类也提供了对异常结果的处理接口
- 宏观分类
1. 产出型或者函数型：就是用上一个阶段的结果作为指定函数的参数执行函数产生新的结果。
      这一类接口方法名中基本都有apply字样，接口的参数是(Bi)Function类型。
2. 消耗型或者消费型：就是用上一个阶段的结果作为指定操作的参数执行指定的操作，但不对阶段结果产生影响。
      这一类接口方法名中基本都有accept字样，接口的参数是(Bi)Consumer类型。
3. 不消费也不产出型：就是不依据上一个阶段的执行结果，只要上一个阶段完成（但一般要求正常完成），就执行指定的操作，且不对阶段的结果产生影响。
      这一类接口方法名中基本都有run字样，接口的参数是Runnable类型。
4. 还有一组特别的方法带有compose字样，它以依赖阶段本身作为参数而不是阶段产生的结果进行产出型（或函数型）操作。

- 多阶段的依赖：一个阶段的执行可以由一个阶段的完成触发，或者两个阶段的同时完成，或者两个阶段中的任何一个完成。
1. 方法前缀为then的方法安排了对单个阶段的依赖。
2. 那些由完成两个阶段而触发的，可以结合他们的结果或产生的影响，这一类方法带有combine或者both字样。
3. 那些由两个阶段中任意一个完成触发的，不能保证哪个的结果或效果用于相关阶段的计算，这类方法带有either字样。

### fork/join
- Fork/Join框架其实就是指:
    1. ForkJoinPool作为线程池
    2. ForkJoinTask(通常实现其三个抽象子类)为任务
    3. ForkJoinWorkerThread作为执行任务的具体线程实体这三者构成的任务调度机制.
- 基础
1. fork阶段，不断递归的将任务分解为较小的子任务，知道这些子任务足够小并被执行。（递归思想）
2. join阶段，在任务分解处理完毕后，将各个子任务结果合并。如果任务返回void，就等待子任务完成。

- 源码解释
1. ForkJoinWorkerThread有一个属于自己用来存放任务的双端队列workQueue。work-stealing算法通过这种存储结构来平衡线程负载。
2. 一个双端队列workQueue中存放多个ForkJoinTask任务。