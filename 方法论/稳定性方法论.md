### 常见的监控指标纬度
1. 流量QPS (流量可以更好地理解服务需求。此信号可帮助您决定何时需要扩大服务规模以应对不断增长的客户需求，或缩小服务规模以提高成本效益。)
2. 延迟(各种接口的耗时)
3. 错误(服务的可用性)
4. 饱和度(服务器资源利用率的度量，资源利用率达到 100% 之前，服务性能也会缓慢下降)

### 稳定性建设：
1. 定义指标, (1. 定义可用性指标，99.9%可用性，2. 故障度量考核指标， 3. 服务分级)
2. 高可用系统的架构设计，要从产品需求、代码开发、运维部署、故障管理等系统全生命周期进行全方位去考量和设计。核心思想就是：故障事前：故障预防，总结经验，做到有智慧的绕开问题。故障发现：及时发现，通过完善观测平台及时发现问题吧。故障恢复：快速恢复，做好应急预案降低故障影响。故障总结：复盘总结故障问题，层层剖析问题产生的原因，由表及里分析问题发生的本质。
   2.1 从产品角度：主要是故障发生后的兜底策略
   2.2 从代码研发：1. 首先要对研发层面有一个代码架构规范，例如编码规范，api规范， 技术文档规范、项目层次规范、模块规范、依赖规范、log规范等  
   2. 设计阶段：高可用的架构设计， 做架构分层(接入层，应用层/服务层，数据层)，每一层做好各自的高可用
   2.1 接入层： 域名高可用(防止ddos，使用https防dns劫持)，api的安全，限流与防刷策略。
   2.2 应用层： 无状态设计与水平扩展，幂等设计，容错机制，降级处理机制，
   2.3 数据层： 做好cap，事务性，数据备份与恢复
   3. 编码阶段：要有单元测试，代码审查工具等。
   4. 运行维护阶段： 针对不同业务场景，专门优化(库存平台稳定性建设实践)
   2.3 从部署运维：1. 规范上线流程， 要有灰度发布 2. 监控报警，
   2.4 从故障管理：1. 故障前，做好容量评估，建立常态化压测， 2. 变更机制预防，做好上线审批与周知机制。
   2. 故障发现： 完善监控报警管理，进行报警治理，不断优化报警方式指标
   3. 故障恢复： 做好应急预案， 切流系统工具


### 稳定性建设中存在的风险点和难度
1. 存量风险识别的难度.(如何发现这些问题). 工单和报警太滞后。需要从整体上排除风险,要准确评估整个域的稳定性并识别其中的风险.
2. 风险治理的难度. (1.排期不够问题, 2.治理本身带来的变更风险。 为了预防可能发生的故障，反而引入了变更故障)
3. 变更复杂度 (代码债务阻碍了变更，无论是业务的迭代还是技术的治理，都会提升变更的风险。 一个应用往往要经历多人维护，就必然出现信息传递的损失，理解不足)
4. 增量风险识别的难度.
    1. 变更可见性,这里所说的可见性，不仅仅是变更执行者本人的知晓，更是整个团队乃至所有相关方共同的认知, 其他同学进行二次确认
    2. 方案可控性，由于整体链路的复杂性和不可控性，对于变更方案的风险可控性评估就显得异常困难。
    3. 人员可靠性： 那么怎样在各种各样的变更中，去保障人员的下限，不要让这种人员的波动性影响到系统的稳定性；甚至尽可能让人员保持他们的高上限


0. 排期不足的问题
   需要业务团队内部从主观层面建立对稳定性的一致认知：即业务团队需要针对本团队业务的重要性、发展阶段、风险情况进行综合评估，确定好稳定性建设在本团队中的重要程度。这个共识就是业务团队确定好稳定性建设将在团队总投入中的时间占比。这个占比可以在迭代维度进行波动，但周期拉长到季度、年维度的时候，是需要保持在一个符合预期的比例的。
   1.稳定性短期价值不明确带来的争议，这块我们通过建立团队的稳定性共识得到彻底的解决。
   1.1 团队成员是否充分了解稳定性的重要性。 (如果长期不提及稳定性，其重要性就会在潜意识中随时间弱化)
   1.2 团队成员是否愿意花费时间和精力去评估并解决稳定性风险。 (权责到人,负责固定的应用。通过设置稳定性红线或进行故障复盘来进行必要的惩罚)
   1.3 团队成员能否识别风险，并设计有效的解决方案。(1. 定期分享， 2. 沉淀组内/域内的稳定性知识库，将团队的能力沉淀下来， 3. 寻求他人帮助)
   2.稳定性建设的复杂性和风险性：
   2.1 增量风险预防：安全生产规范整个存在的意义就是为了通过流程来控制增量风险。
   2.1.1 需求变更。几乎所有的相关方，都能够准确知道变更内容、变更方案和变更时间，并共同确认过变更风险。正因为这些环节在现有的需求流程中多半能够充分落实，因此需求变更带来风险的概率是相对较低的。
   2.1.2 技术团队内部的 技改需求、curl、数据订正、Ark变更等操作，在技术部多次管控加码之前，这些变更操作发生问题的概率远高于需求变更。其原因正是由于这些变更可能就是某个研发顺手操作了，其可见范围极小。根本没有相关方进行多轮有效的二次确认操作，
   2.1.3 其他类似的案例还有业务方突然执行了大量的业务变更操作，突然进行了某项营销活动导致引入远超预期的流量等等，这同样也是由于变更的可见性并未被技术团队感知，而导致的变更风险。
   2.2 风险治理的难度：该问题先可以通过架构治理进行分而治之，将大问题拆解成若干个小问题；再通过安全生产规范，控制每次解决小问题引入风险的概率。
   2.3 存量风险识别的难度：
   2.3.1日常巡检有助于发现存量风险的苗头，(或是慢SQL、或是慢接口，或是cpu突刺。包括业务数据量是否逐步增长到了危险的范围，各项活动/配置是否临近过期，上下游的调用量是否接近容量上限……等)
   2.3.2 意识培养则有助于对单应用风险的摸排，
   2.3.3 架构治理则对应了对于应用间、甚至整个域内的依赖链路风险评估和治理。
   1. 领域建模、高内聚低耦合、OO等的架构原则，反映到变更风险中，就是控制了变更复杂度。
   2. 资源隔离的架构设计，则是专门用于控制爆炸半径避免相互影响.
   3. 还有一个关键点，那就是抓住主要矛盾，先从最核心的业务场景开始治理。如果没有考虑好治理优先级，那么茫茫多的场景和链路就会成为一个交织在一起的毛线球，是无法进行抽丝剥茧逐一治理的。



### 稳定性常问的问题：
0. 当前容量怎么样。
1. 风险点在哪里，瓶颈在哪里，怎么修复
2. 怎么发现风险，怎么扩容
3. 出现问题怎么降级，怎么修复


### 学练机的核心数据：
拿到数据：当前系统的数据，各个维度的数据
1. 各个服务的数据，qps， 耗时
2. 总体服务的数据

### 日志如何打印： 
0. 日志只能多，不能少，否则排查问题不好查
1. 关键信息打印(studentId, 唯一key， 入参，出参，关键路径)
2. 考虑如果流量很大时，如何快速定位问题， 否则难以承受损失



### 读取文章
1. 掘金相关的稳定性文章， 包括：各个领域的稳定性建设，比如下单，库存，商品等。
2. 微信每日文章精选中的稳定性相关。