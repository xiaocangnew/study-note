### 快的原因：
  * 1.单进程单线程
  * 2.完全基于内存
  * 3.数据结构简单
  * 4.使用i/o多路复用（I/O 多路复用模块，解决多个用户读写问题）
  * 5.使用底层模型不同，Redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；
- 单线程优点：
  * 代码清晰简单
  * 不存在切换cpu导致的开销
  * 不用考虑锁的问题，不用加锁和释放锁，没有因为死锁带来的性能消耗
- 单线程缺点：
  无法发挥多核cpu的优势，只能是单机多实例来完善。
  
- QPS 达到10w+
  在连接数为1w时，有8-9w的QPS；在连接数为3w时，依然有6w+的QPS； 在连接数为6w时，有5w的QPS，

### redis的优缺点：
- 优点：
   1. 速度快；
   2. 支持丰富的类型(vs mongodb等)
   3. 支持事务，原子性操作
- 缺点：
   0. 是中间件，有系统可用性降低和复杂性升高的问题
   1. 缓存和数据库双写一致性问题
        一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。
        redis只能保证最终一致性, 降低不一致发生的概率，无法完全避免。如果对数据有强一致性要求，不能放缓存。
   2. 缓存雪崩问题
   3. 缓存击穿问题
   4. 缓存的并发竞争问题

### redis 各个数据类型的使用场景
1. String类型常用的场景有以下这些：
      1. 缓存结构体信息： userId-> userBean(转为json存储)
      2. 计数功能
2. list列表
      1. 消息队列，可以利用List的PUSH操作，将任务存在List中，然后工作线程再用POP操作将任务取出进行执行
      2. 粉丝列表等功能；
3. zset的场景
      1. 各类热门排序场景
4. set的场景
      1. 去重场景: 每个用户只能参与一次活动、一个用户只能中奖一次等。
      2. 求交集、并集、差集等操作，可以非常方便的实现如共同关注、共同喜好、二度好友等功能
5. hash的使用场景：
      1. 保存结构体信息.不同于字符串一次序列化整个对象，hash可以对用户结构中的每个字段单独存储

  
### redis的使用场景，在公司业务里的使用
1. 热点数据的缓存
      1. redis无法保持交易数据强一致性，公司业务是直接从数据库中获取，
      2. 对于一些热点缓存，比如quote,有效时间只有几秒, 用了guavacache, 这里redis和cache效果一样，但是guavacache方便点，直接get就可以来，redis代码比较多
2. 限时业务的使用
     1. openfix需求中使用了这个特性，保持1天
     2. 交易check的快照，用于问题排查，保存7天
3. 分布式锁使用
4. 计数器相关问题
    redis由于incrby命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成;
5. 排行榜相关问题
   关系型数据库在排行榜方面查询速度普遍偏慢，所以可以借助redis的SortedSet进行热点数据的排序。
6. 延时任务的使用
7. 消息队列
8. 订阅通知 
    - 原理
       1. 底层使用dict， key-value模型为： channel-List<consumer>.
    - 使用场景
       1. 异步消息通知
           系统在调支付平台的时候，我们可以用回调的方式给支付平台一个系统回调接口来通知我们支付状态；
           可以利用Redis的发布订阅来实现：支付平台发布支付结果到channel，我们系统订阅这个channel获得结果。
       2. 任务通知
           把任务发布到一个channel， app订阅这个channel，接受任务；
       3. 参数刷新重载
       4. 微博订阅推送
     - 存在问题
        1. 数据可靠性无法保证， 是否发送成功，是否接受成功，队列是否持久化；
        2. 扩展性太差
        3. 资源消耗高。消费者则需要单独占用一个Redis的链接

   
### 虚拟内存
- redis为什么没有使用操作系统提供的虚拟内存而是在用户态实现了自己的虚拟内存机制？
* 操作系统最小单位为4k/页，而redis大多是小对象，所以一个操作系统页上有很多redis对象；
* redis的集合对象可能分布于多个操作系统页上，但只有10%的key经常被访问，但操作系统认为是活跃的，这样只有当内存真正耗尽才会进行页的交换
* 相对于操作系统，redis可以对对象进行压缩后再进行保存磁盘（10倍的样子），这样能减少io
    
- 虚拟内存相关配置：
    1.vm=enabled yes   开启虚拟内存
    2.vm-swap-file  /tmp/redis.swap   交换出来的value的保存路径和文件名
    3.vm-max-memory  268435456  内存上限达到后开始交换，建议为总内存的60%-80%
    4.vm-page-size 32    每个redis页的大小为32个字节
    5.vm-pages 134217728  多少个交换页，用来计算交换文件的最大值
    6.vm-max-threads 8  用于执行交换操作的线程。0表示用主线程进行交换，这是阻塞的，不利于相应
    
### redis内存模型
1. 系统开销 = 主进程本身运行肯定需要占用内存，如代码、常量池等
2. 内存碎片; 这个不算到used_memory中
3. used_memory = 缓冲区(客户端缓冲区、复制积压缓冲区、AOF缓冲区) + redis存储的数据；

- 内存占用查看
* used_memory：Redis分配器分配的内存总量
* used_memory_rss：总内存占用= 系统开销 + used_memory + 内存碎片
* mem_fragmentation_ratio：内存碎片比率(=used_memory_rss / used_memory； 比率稍>1合理；>1.5内存碎片率大，<1正在进行swap)
* mem_allocator：Redis使用的内存分配器，在编译时指定；可以是glibc\jemalloc\tcmalloc，默认是jemalloc
     1. 内存分配器是为了更好的管理和重复利用内存，分配内存策略一般采用固定范围的内存块进行内存分配
     2. jemalloc将内存空间划分为三个部分：Small-class; Large-class; Huge-class，每个部分又划分为很多小的内存块单位：
     3. 简单来说就是采用不同大小的内存块来存储不同大小的内存对象，比如说一个5kb的对象就会存到8kb的内存块中，那么剩下的3kb内存就变成了内存碎片，不能再被分配给其他对象
     4. 通常在对key做频繁更新操作和大量过期key被删除的时候会导致碎片率上升，可以考虑重启节点的方式重新整理碎片

### redis内存碎片
- 内存碎片产生
    Redis内部有自己的内存管理器，为了提高内存使用的效率，来对内存的申请和释放进行管理。
    Redis中的值删除的时候，并没有把内存直接释放，交还给操作系统，而是交给了Redis内部有内存管理器。
    Redis中申请内存的时候，也是先看自己的内存管理器中是否有足够的内存可用。
    Redis的这种机制，提高了内存的使用率，但是会使Redis中有部分自己没在用，却不释放的内存，导致了内存碎片的发生。
- 清理碎片
  1. 低于4.0版本的Redis
       Redis服务器重启后，Redis会将没用的内存归还给操作系统，碎片率会降下来。
  2.高于4.0版本的Redis
      Redis4.0版本开始，可以在不重启的情况下，线上整理内存碎片。
      自动碎片清理: activedefrag yes
      手动清理：memoery purge
  
### 高并发下如何保证缓存和数据库的数据一致性(只要不是原子性操作，都会有不一致)
- 解决方案：
    - 先更新缓存，后更新数据库
        这种策略纯属凑数，应该没人会这么使用
    - 先更新数据库，后更新缓存(T1T2写库)
        多线程导致出现的脏数据： T1 更新库--> T2更新库--> T2更新缓存--> T1更新缓存
    - 先删除缓存，后更新数据库(T1写，T2读)
        多线程中可能导致脏数据: T1写线程删除缓存 -> T2读线程获取不到缓存 -> T2读线程重新从DB构建缓存 -> T1更新DB
    - (推荐策略)先更新数据库，后删除缓存 (T1读，T2写库) 
        - 多线程中可能导致脏数据: 缓存失效-> T1 请求数据库得到旧值 --> T2更新数据库 --> T2删除缓存 --> T1 将旧值load到缓存
        - 虽然可能有并发问题，但是概率非常小，因为只有当T2更新数据库的时间小于T1读数据库的时间时，才可能发生T2删除缓存比T1 load旧值先发生；
            - 如果小概率事件发生了怎么办：
                - 给缓存设置过期时间(保证最终一致性)；
                - 采用延时双删策略 : 1. 删除缓存--> 写库 --> sleep(500MS) --> 删除缓存,  同时设置合理的过期时间(sleep时间判断： 在读数据业务逻辑的耗时基础上，加几百ms即可。确保读请求结束，写请求可以删除读请求造成的缓存脏数据)
            - 如果删除缓存失败了怎么办：
                - 提供保障重试机制: 使用一个队列存放删除失败的key，消费这个队列；    
        - 会有缓存击穿的问题
    - 异步更新缓存，采用canal
        redis缓存读数据， mysql负责写数据，更新由canal负责；
    - 串行化(终级解决方案)
        1. 先删缓存，将更新数据库的操作放进有序队列中 2. 从缓存查不到的查询操作，都进入有序队列
        2. 串行化需要解决的问题：
           读请求积压，大量超时，导致数据库的压力：限流、熔断
           如何避免大量请求积压：将队列水平拆分，提高并行度。
        3. 有一个可以优化的点，比如一个队列中，连续存在多个更新缓存请求串在一起是没意义的，例如有好几个相同key的查询。
           操作应该优化：如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接让后面的读请求阻塞个200ms左右（参考guavaCache）.
           然后再次查询缓存，如果缓存没有值就查数据库，拿到结果后不用更新缓存，直接返回给页面即可。
- 应用场景，是以写为主还是以读为主
     1. 以读为主，是先更新数据库，后更新缓存
             
### 数据淘汰机制：
- 当内存使用达到设置的最大阀值95%时，内存的数据会开始和磁盘产生频繁的交换 (swap，慢5个数量级)。交换会让Redis的性能急剧下降
  当内存数据集大小达到maxmemory后，redis就会根据maxmemory-policy配置项配置的策略来进行数据淘汰。
* 从设置过过期时间的数据集中：  volatile-lru算法，volatile-random算法，volatile-ttl算法（time to live）
* 从全数据集中：allkeys-lru算法，allkeys-random算法，noeviction永不过期(写入报错，只可以查询)。   

- 使用策略规则：
1.如果数据分为冷数据和热数据，也就是一部分数据访问频率高，一部分数据访问频率低。则使用allkeys-lru
2.如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random
3.或者写一个定时任务，定期将高频数据同步到redis中

- 注意
  使用expire time会消耗额外内存。

- 如何配置
* 修改redis.conf的maxmemory，设置最大使用内存：maxmemory 1024000
* 修改redis.conf的maxmemory-policy，设置redis缓存淘汰机制： maxmemory-policy noeviction

- 如何查看
* info stats。信息中的evicted_keys字段显示的是被回收删除的keys数量

### redis采用的过期策略   redis采用懒惰删除 + 定期删除结合方式
- 业界对于过期一般有3中策略：
* 定时删除--为key创建timer---保证内存及时释放---占用cpu来跑timer，创建timer耗时
* 懒惰删除--当使用key时才判断是否过期然后删除--占用cpu少，因为只删除当前key ---可能发生内存泄漏
* 定期删除--每隔一段时间执行一次删除过期key操作--优缺点都剧中---难点：定期时长的选择，游标的记录位置保存
   - 定期删除流程：
     1.Redis每秒调用10次(hz参数决定)activeExpireCycle函数；
     2.每次随机获取20个带有生存时间的键。
     3.删除其中已过期的键。
     4.如果其中过期键超过25%(即大于5个键是过期的),activeExpireCycle函数会重新调用，
      开始第一步(如果大量KEY同时过期，可能引起Redis性能抖动)。

- 大量过期键堆积，最直接影响是浪费内存空间；另外还会有些”灵异现象”
   1.Master的键个数比Slave多20%
   2.读定分离时，应用程序读取Slave时能返回快过期的键
   3.Redis scan或keys出来的键个数，远小于dbsize返回的个数
   4.高并发情况下，可能出现性能抖动,定期删除最坏可占25%的CPU时间片
   
- 从两个方面解决大量过期键
    - 降低过期键产生的速度；
       1.业务设计键的过期时长时，是否考虑过期键生成的速度；能否加大过期键的生存时间。 如天气缓存集群，大量的键要求1分钟过期，从产品需求角度，能否设置更大。
       2.尽量避免使用大实例，控制Redis单实例的键个数(如1kw)，可有效控制单个实例过期键产生的速度；拆分为更多的分片，加大集群定期删除的速度
    - 加快定期删除的速度。
       1.适当调大hz的值,增大每秒定期删除的次数；建议调整60，官方建议小100； 因调用serverCron除了过期删除动作外，还有很多其他操作，可能占用过多的CPU时间片
       2.主动触发Redis”惰性删除策略”,通过scan命令扫描整个实例的键，Redis会删除所有已过期的键。

### 持久化
* 手动触发：   lastsave 指令可以查看最近的备份时间
   - SAVE：阻塞Redis的服务器进程，知道RDB文件被创建完毕
   - BGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程 
* RDB半持久化(默认):不定期的通过异步方式(BGSAVE)保存到磁盘上.(redis database)
  - 没有高可用，但是性能更好。有利于灾难恢复，启动时效率跟高
  - 配置：rdb save 900 1 ;每900秒后，如果至少一个key变化，dump
* AOF全持久化:每一次数据变化都异步地写入到一个append only file(aof)里面
  - 能保持高可用，但是性能低点，相同数据量时aof文件比rdb文件更大
  - 配置：aof  appendfsync always//everysec//no
  
- RDB对性能的影响，有什么方法可以规避吗？
   1.每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程(cow技术)，并由子进程来进行实际的持久化工作。
   2.在数据集比较庞大时，生成子进程和rdb文件可能会非常耗时，造成服务器在某某毫秒内停止处理客户端。
   3.通常的设计思路是利用Replication机制来弥补RBD性能上的不足，达到了数据可持久化。
      即Master上RBD和AOF都不做，来保证Master的读写性能，而Slave上则同时开启RBD和AOF来进行持久化，保证数据的安全性。

- aof文件过大时，
     - 重写AOF重写的相关配置，也可以手动出发bgrewriteaof。
         1. auto-aof-rewrite-percentage 100  
         2. auto-aof-rewrite-min-size 64mb  
       这两个配置项的意思是，在aof文件体量超过64mb，且比上次重写后的体量增加了100%时自动触发重写。
    
    - 重写过程
      1. AOF重写并不需要对原有AOF文件进行任何的读取，是通过读取服务器当前的数据库状态来实现的。
      2. 同一个key的值，只保留最后一次写入 ,已删除或者已过期数据相关命令会被去除
      3. Redis增加了一个AOF重写缓存，这个缓存在fork出子进程之后开始启用，
          Redis服务器主进程在执行完写命令之后，会同时将这个写命令追加到AOF缓冲区和AOF重写缓冲区
      4. 子进程完成后通知主进程，
          "主进程AOF缓冲区内容追加到新aof文件”和“对新的AOF文件进行改名，覆盖原有的AOF文件。”这两个步骤会造成主进程阻塞，

  
###主从复制 (保持数据一致性，是异步过程)
- 1.初始化时执行全量同步
1）slave-->发送PSYNC命令-->master
2）master-->BGSAVE命令-->生成RDB文件 + 缓冲区记录此后执行的所有写命令；
3）BGSAVE执行完后，master-->rdb文件-->slave + 继续记录被执行的写命令；
4）slave-->收到rdb-->丢弃旧数据 + load rdb；
5）slave-->rdb处理完毕-->发信号到master，master发送缓冲区中的写命令；
6）slave-->rdb载入ok-->开始接收命令请求 + 执行来自master缓冲区的写命令；

- 2.正常工作时执行增量同步(命令传播)
* master每执行一个写命令就会向slave发送相同的写命令，slave接收并执行收到的写命令

- 3.心跳检测
在命令传播阶段，slave默认每秒一次的频率向master发送命令检测主从服务器连接是否正常
检测命令丢失，主服务器接收到从服务器的命令之后会检查从服务器的偏移量是否和主服务器的一致，
如果不一致会把积压缓冲区中的从服务器偏移量后面的命令发送到从服务器.

- sync 和 psync
   - redis2.8以前用的时sync，对于slave断线重连master，需要重新全量复制master，即使是很小的时间间隔，带来巨大的浪费；
   - redis2.8以后，使用psync替代sync， psync有完整同步和部分同步功能；
      - 基础概念
         1.主服务器的复制偏移量( replication offset )和从服务器的复制偏移量。
         2.主服务器的复制积压缓冲区(replication backlog)--- master在把命令给slave时，也会放入积压缓冲区中。
           slave断线重连复制时，如果offset偏移量之后的数据还在积压缓冲区中，则进行部分复制
         3.服务器的运行ID(run ID)。 slave对应的master如果runId相同，则进行部分复制，否则全量复制

- 注意
* slave在同步未完成时使用老数据
* BGSAVE命令 = fork子进程 + copy on write
      - copy on write 原理
           fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。
           当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，
           于是触发页异常中断（page-fault），陷入kernel的一个中断例程。
           中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份
      - copy on write 优缺点
           优点是：减少分配和复制大量资源时带来的瞬时延迟， 减少不必要的资源分配；
           缺点是：如果fork后父子进程都还需要进行写操作时，就会产生大量的分页错误；(总体来看，Redis还是读操作比较多)
* redis使用异步方式进行数据同步，是弱一致性的，但是性能比同步方式好

### sentinel (侧重高可用)
- 应用程序连接到哨兵端口，通过指定不同的master名称连接到具体的主副本。
- 哨兵的作用： 1.监控 2.通知  3.自动故障转移 4.配置提供者
- 哨兵节点个数至少要有三个， 只有一个会造成单点， 两个的话无法选举。
- 只有master提供服务，slave不提供服务。(浪费资源，无法进行主从分离)
- 主观下线和客观下线：
   主观下线就是单个sentinel认为某个服务下线
   客观下线就是大部分哨兵节点都同意下线操作
- 哨兵leader选举过程
   
### redis cluster(侧重水平扩展)
1. 几年前，redis要做多节点，需要借助中间件(codis, twemproxy)。业务和中间件交互，中间件来和redis交互。
2. 最近几年，redis出了自己的cluster，可以进行每个节点上部署一部分数据，同时每个master上可以挂slave，自动确保自动切换。
3. 现在版本，大家都是用redis的cluster。
4. redis cluster沒有使用一致性hash算法，而是使用了hash slot算法。
     1.一个集群只能有16384个槽，对每个key计算CRC16值，然后对16384取模，获取slot。
     2.集群中每个master都会持有部分slot。增删master时就会移动对应的slot，移动成本很低。
     3.可以用hash tag指定key放在哪个slot上面，例如 set key:{100}
5. 节点通信方式：(redis采用gossip通信，节点间通信端口：服务提供端口 + 10000)
     1. 集中式通信(比如zookeeper，所有元数据都在zookeeper上)
          优点： 时效性很好；
          缺点： 元数据更新存储都在一个地方，导致压力比较大 
     2. 分布式通信(gossip通信，每个节点都保存有所有元数据)
         - 协议消息类型： ping / pong / meet /fail
            - ping消息：发送节点自己的状态和维护的元数据，还有1/10其他节点的信息。
                1.ping很频繁，而且要携带元数据信息，所以会加重网络负担。
                2.每个节点每秒会执行10次ping，每次会选择5个最久没通信的其他节点;
                3.如果和某个节点通信延时达到cluster_time_out/2,会立即进行ping，避免落后时间太多。
6. 高可用和主备切换原理(和哨兵模式很相似)
   - 判断节点宕机
      和哨兵模式一样，有主观下线和客观下线； 如果某个节点在cluster_time_out内没有pong回应，就认为是主观下线；
       有半数master 认为该node下线，就是客观下线。
   - slave选举
      1. 只有于master断开连接时间没超过cluster_time_out * cluster_slave_validity_factor， 就有资格进行选举；
      2. 选举根据复制数据的offset来设置选举时间，offset越大，选举时间越靠前，越优先。 
      3. 所有master node进行slave选举投票，需要符合半数原则。
7. 客户端发送请求时
   1. 在集群模式下，Redis接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点。
       如果节点是自身，则处理键命令；
       否则回复MOVED重定向错误，通知客户端请求正确的节点。这个过程称为MOVED重定向(cluster node并不负责转发)
   2. Redis客户端采用Smart客户端支持集群协议。
       Smart客户端通过在内部维护slot→node的映射关系，本地就可实现键到节点的查找，从而保证IO效率的最大化，
       而MOVED重定向负责协助Smart客户端更新slot→node映射。
   3. 请求都发往master， slave只用来做备份和容灾
8. cluster因为要做master选举，所以必须大于3个节点
      
- redis为什么使用hash slot，而不是用一致性hash
    cluster作者认为：两者效率差不多，但是slot更简单。

- 为什么是16384（2^14）个slot
1. 在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，
2. 虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，
3. 16384=2^14=16k，字节。在发送心跳包时使用char进行bitmap压缩后是2k（2 * (8 bit) * 1024(1k) = 2K），也就是说使用2k的空间创建了16k的槽数。
   65k压缩后就是8k（8 * 8 (8 bit) * 1024(1k) = 8K），也就是说需要需要8k的心跳包，作者认为这样做不太值得；
   并且一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择。

### redis高可用方案
* 1.哨兵模式(侧重高可用)
  - 优点：
   1)解决主从模式下的高可用切换问题；
   2)Redis数据节点的线性扩展，简单加机器；
  - 缺点：
   1)资源浪费，slave节点作为备份节点不提供服务；
   2)主要是针对master的高可用做切换，对slave做SDOWN下线操作（不做ODOWN），并不执行故障转移。
   4)不能解决读写分离问题，实现起来相对复杂

* 2.cluster(侧重扩展)
  - 优点
   1)无中心架构；
   2)数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布；
   3)可扩展性：可线性扩展到1000多个节点，节点可动态添加或删除；
   4)高可用性：部分节点不可用时，集群仍可用。通过增加Slave做主备模式下的备机，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升；
   5)降低运维成本，提高系统的扩展性和可用性。
  - 缺点：
   1)Slave 在集群中充当“冷备”,
   2)批量操作限制，如使用 mset、mget 目前只支持具有相同slot值的Key执行批量操作。
   3)事务操作支持有限，只支持多key在同一节点上的事务操作，当多个Key分布于不同的节点上时无法使用事务功能。
   4)不支持多数据库空间，单机下的redis可以支持到16个数据库，集群模式下只能使用1个数据库空间，即db0 。

### 缓存穿透（一个一定不存在缓存及查询不到的数据）
由于缓存是不命中时被动写的，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。
1.缓存空值，但是它的过期时间设置的比较短
2.bloomFilter 布隆过滤器，
    优点:  空间占用小 /性能强 
    缺点: 代码复杂度增大 /布隆过滤器不支持删值操作 / 存在误判率
    - 原理： 
     1) 一个key有多个hash算法
     2) 多个hash值取余
     2) 一个key的多个hash值映射到hash表
     
### 缓存击穿解决方案(即热点key过期)
key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，即在key 过期的瞬间大量请求打到数据库上；
1. 使用互斥锁(mutex key):只让一个线程构建缓存，其他线程等待构建缓存的线程执行完(只有得到锁的才能去load)
2. "永远不过期";
    1. 该方案redis设置key时不设置过期时间，而是自己维护一个timeout，当timeout小于System.currentTimeMillis()时，新起一个线程进行异步构建缓存
    2. 在异步成功前，其他查询查的是老值，有一定的数据不一致性;
4. 资源保护：例如hystrix，但有降级的问题。

### 缓存雪崩(大量key同时过期，redis服务挂掉)
1.为有效期增加随机值/统一规划有效期，使失效时间均匀分布(如果集中过期，redis可能会出现短暂的卡顿现象).
2.使用合理的队列数量来避免缓存失效时对数据库造成太大的压力。这种办法虽然能缓解数据库的压力，但是同时又降低了系统的吞吐量。
3.事前(双机房)-->事中(限流降级)-->事后(快速缓存预热,redis数据备份和恢复)

### 找出热点key
1. 凭借经验，进行预估：例如提前知道了某个活动的开启，那么就将此Key作为热点Key
2. 客户端收集：在操作Redis之前对数据进行统计
3. 抓包进行评估：Redis使用TCP协议与客户端进行通信，通信协议采用的是RESP，所以能进行拦截包进行解析
4. 在proxy层，对每一个 redis 请求进行收集上报
5. Redis自带命令查询：Redis4.0.4版本提供了redis-cli –hotkeys就能找出热点Key(如果要用Redis自带命令查询时，要注意需要先把内存逐出策略设置为allkeys-lfu或者volatile-lfu，否则会返回错误)

### 使用过Redis做异步队列
- 使用list结构作为队列， 使用lpush , lpop, blpop

### redis如何实现延时队列
- 使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，
   添加消息： zadd key score1 value1
   消费消息： zrangebysocre key min max withscores limit 0 1
   
### 分布式锁
1. setnx,会有死锁问题，线程在未设置expireTime就异常，则永远无法释放锁；
2. 使用jedis.set(lockKey, requestId, "NX", "PX", expireTime); // requestId是value，全局唯一，用来保证分布式锁的解铃还须系铃人， nx为不存在时才设置，存在时什么也不做， px设置超时时间

###如果突然机器掉电会怎样？
取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。
但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

### redis 如何保证高并发
1. Redis通过主从架构，实现读写分离，主节点负责写，并将数据同步给其他从节点，从节点负责读，从而实现高并发。
2. 如果缓存要容纳的数据量很大，需要使用redis集群

### redis的并发竞争
- redis本身是单线程的，并不存在并发竞争的问题；多客户端同时set某个key导致竞争
      1. 分布式锁+时间戳方案：
         只有获得锁的进程才能取更新redis，同时更新时带上数据库的时间戳，如果redis中的值比数据库中的值新，就不更新；
      2. 利用消息队列
         在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。
         把Redis.set操作放在队列中使其串行化,必须的一个一个执行。

### redis的 CAS
- 乐观锁介绍：
    watch指令在redis事物中提供了CAS的行为。为了检测被watch的keys在是否有多个clients同时改变引起冲突，这些keys将会被监控。
    如果至少有一个被监控的key在执行exec命令前被修改，整个事物将会回滚，不执行任何动作，从而保证原子性操作，并且执行exec会得到null的回复。
- 乐观锁工作机制：
    watch命令会监视给定的每一个key，当exec时如果监视的任一个key自从调用watch后发生过变化，则整个事务会回滚，不执行任何动作。
    注意watch的key是对整个连接有效的，事务也一样。如果连接断开，监视和事务都会被自动清除。
    当然exec，discard，unwatch命令，及客户端连接关闭都会清除连接中的所有监视。
    还有，如果watch一个不稳定(有生命周期)的key并且此key自然过期，exec仍然会执行事务队列的指令。
    
### redis中lru算法如何实现， lfu算法实现
- lru缓存淘汰算法(基于概率的猜测)：
   1. Redis并没有使用双向链表实现一个lru算法(linkedHashMap)
   2. 在redisObject结构里有个lru字段，记录的是最后一次的访问时间戳；
   3. 初始时随机选3个Key放入pool里(maxmemory-samples=3)
   4. 每次都拿出3个key，如果这3个key里的lru时间戳小于pool里面最小的，那么将其放入pool里
   5. 当需要进行淘汰时，直接从pool里进行淘汰lru时间戳最小的；
- lfu算法实现
   1. lru在继续增加采样的key或者pool的大小，作者发现很难进一步优化lru算法
   2. 记录一个key被访问的次数,那么经常被访问的key最有可能再次被访问到,访问次数最少的最应该被逐出。
   3. lfu本质上是一个概率计数器，随着访问次数的增加,counter的增加会越来越缓慢.
        server.lfu_log_facotr(默认为10)记录了访问次数和counter的关系；
   4. lfu随着分钟数对counter做衰减, 给时间也增加了一定的权重。
   5. 淘汰时仍然是一个pool,随机选取10个key,counter最小的被淘汰
   
### redis 单实例可以存储多少个key
1。官方说明是： 上限是2的32次方个key，实际测试时至少可以存储2.5亿个key。 
2。 存储时限制在value，而不在key上。 redis.conf配置maxMemory，超过限制则拒绝写入。
     参数能很好的保护好你的Redis不会因为使用了过多的物理内存而导致swap,最终严重影响性能甚至崩溃