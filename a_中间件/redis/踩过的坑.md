[性能排查手册](https://www.cnblogs.com/mushroom/p/4738170.html)

### 内存操作是0.1us --3个数量级-->千兆网卡延时约0.2ms --2个数量级--> 磁盘操作是10ms

### redis 开发规范
1. redis 使用主从/集群版， 根据数据规模来判断
   请评估请求量和容量[内存昂贵]，选择适合的架构
           每秒请求量不大于20000且容量小于10GB，请申请主从版；其他情况请申请集群版。
           注意点：
            1、集群版业务要注意事务、Lua脚本、多key操作中保证操作中的key不能跨slot，否则报错；
            2、mset、mget获取多个key的操作由于跨slot耗时增加，需要计算key的slot进行分组 (所以业务使用集群时，mget，hmget获取多个key的操作由于跨slot耗时增加，可以通过先计算key的slot进行分组，然后通过pipeline加速)
2. Redis存储和缓存默认的淘汰策略不同，2种功能不要混用同一个Redis集群
3. key名字的长度控制在32个字符以内，节省内存 比如使用：nan:mn:atms:123
   value的元素个数要控制长度，避免出现bigkey。 单个value大小控制在10KB以内
   Redis不要存放业务日志类、图片类、评论类等大文本。使用hash、set、zset、list单个key控制在1万个元素左右，value大小控制在5KB
3. Redis做缓存，多用string类型，key数量要多控制其中的元素个数，解决了热点key，也解决了key过期后重建缓存消耗时间的问题
      业务对key设置过期时间时，要求每个key过期时间随机，因为集中key的过期风暴会影响Redis的性能
      少使用lua脚本，使用evalsha时程序使用 SCRIPT EXISTS先判断脚本是否存在，避免NO SCRIPT错误
      缓存雪崩时，存储层的调用量会暴增，要考虑Redis缓存层的高可用和后端服务提供降级，避免整个系统不可用
      业务使用集群时，mset、mget获取多个key的操作由于跨slot耗时增加，可以通过先计算key的slot进行分组，然后通过mxxx、pipeline加速
      使用List类型时，要控制队列中的长度建议在3000以下，业务需对队列长度和消费挂掉进程状态进行监控，避免出现队列不消费的情况
5. 命令调用规范
   建议不要使用eval和evalsha Lua脚本实现业务逻辑，使用代码实现相关功能【强烈建议】
           1、Redis的单线程模型串行执行命令，上述命令包着多行操作执行占用带宽，耗时会比较长，很影响Redis的吞吐量
           2、主从版请求量遇到瓶颈要升级到集群时，上述命令要修改保证操作中的key不能跨slot，否则报错
           3、某些SDK（如Redisson），很多高级实现都内置使用lua，开发者可能莫名走入CPU运算风暴中，须谨慎
   批量操作命令指定步长控制元素个数（<=500），不要使用0,-1操作【必须】
          hgetall、lrange、smembers、zrange、zrerange命令操作时指定步长或scan迭代，避免扫描出现慢查询阻塞请求出现超时
   删除key时，不要使用del命令，使用scan方式迭代清理【必须】
          list删除使用ltrim，set删除使用sscan + srem，hash删除使用hscan + hdel，sortedSet删除使用zscan + zrem
   禁止使用影响线上业务的高危命令【必须】
          禁止业务功能使用keys、flushall、flushdb、monitor、bgsave、bgrewriteaof，Redis服务端考虑使用rename机制禁止命令
   不要使用非database 0库，默认使用0库【必须】
           Redis默认使用0库，使用select其他库存在切库的开销；更易自动化运维管理，如 scan/dbsize 命令只用于当database
   建议业务程序不要使用鸡肋的Redis事务功能【建议】
          1、Redis的事务功能较弱(不支持回滚)
          2、集群中，事务中多key命令保证操作中的key不能跨slot，否则报错
6. redis边界的三角形
       高计算消耗(lua并发)
       高网络消耗(大value，keys扫表， 大batch操作)
       高存储消耗(大key)



### redis 慢查询
1. redis中比较耗时的命令
    1.keys [pattern]模式查询 O(n)
        keys hello* 以hello开头的key值。
    2.sort 主要对List，Set，Zset来进行排序。
        sort命令的时间复杂度是O(n+mlog(m))，其中n是排序列表（集合和有序集合）中元素的个数，m是返回元素的个数。
        Redis在排序前会建立一个长度为n的的容器来存储待排序元素，虽然是一个临时的过程，但是多个较大数据的排序操作则会严重影响系统的性能。
        在使用这个命令的时候：1.尽可能减少n和m的数量; 2.在slave节点中进行。
    3.exists key_name:查询key是否存在
       查询本身是o(1)的操作，但是在exists函数中有清除过期键的逻辑；
    4.smembers命令：用于获取集合全集
       如果一个集合中保存了千万条数据量，一次取回会造成处理线程的长时间阻塞，时间复杂度O(n）
       在设计时，我们可以控制集合的数量，将集合数一般保持在500个以内；
       在取集合的时候可以考虑使用SRANDMEMBER key [count]；随机返回集合中的指定数量，当然，如果要遍历集合中的所有元素，这个命令就不适合了；
    5.mset,mget也是O（n）
2. 生成RDB快照文件时，save命令会带来阻塞：
       虽然使用了copy on write技术，但如果对父进程有写入操作了，那么我们还是要对子进程复制父进程的物理内存，这是非常耗时的，所以在bgsave命令的时候不要对父进程写入
3. 级联阻塞。
       慢查询只记录命令执行时间，并不包括命令排队和网络传输时间。因此客户端执行命令的时间会大于命令实际执行时间。
       因为命令执行排队机制，慢查询会导致其他命令级联阻塞，因此当客户端出现请求超时，需要检查该时间点是否有对应的慢查询，从而分析出是否为慢查询导致的命令级联阻塞。
- 慢查询最佳实践
1. slowlog-max-len 配置建议：线上建议调大慢查询列表，记录慢查询时Redis会对长命令做截断操作，并不会占用大量内存。
     增大慢查询列表可以减缓慢查询被剔除的可能，例如线上可设置为1000以上。
2. slowlog-log-slower-than 配置建议：默认值超过 10 毫秒判定为慢查询，需要根据 Redis 并发量调整该值。
    由于Redis采用单线程响应命令，对于高流量的场景，如果命令执行时间在1毫秒以上，那么Redis最多可支撑OPS不到1000。因此对于高OPS(operation per second）场景的Redis建议设置为1毫秒
4. 日志丢失。由于慢查询日志是一个先进先出的队列，也就是说如果慢查询比较多的情况下，可能会丢失部分慢查询命令.
    为了防止这种情况发生，可以定期执行slow get命令将慢查询日志持久化到其他存储中MySQL。

- 慢查询 问题排查和优化
1.info stats 命令。信息里的total_commands_processed字段显示了Redis服务处理命令的总数
2.Redis-cli --latency -h 127.0.0.1 -p 6379  查看client的延时时间
3.在客户端输入:slowlog get，默认命令执行时间超过10ms的记录
4.在Redis-cli工具中输入info clients 查看客户端连接数。默认最大1w。若是看到连接数超过5k以上，那可能会影响Redis的性能
       配置最大客户连接数： 在redis.conf中配置maxclients， 超过则拒绝连接;

* 分析解决Redis性能问题，通常需要把延迟时间的数据变化与其他性能指标的变化相关联起来。
  命令处理总数下降的发生可能是由慢命令阻塞了整个系统;
  但如果命令处理总数的增加，同时内存使用率也增加，那么就可能是由于内存交换引起的性能问题
  
- 避免延时
* 管道命令
* 避免大集合操作

### redis [内存膨胀问题](http://www.dataguru.cn/article-267-1.html)
redis对于5种类型的存储， 都是使用hash数组形式，称为bucket桶(本身是个dictEntry**指针，大小4byte)。 key为键，value再分为5种数据类型：string，list，set，zset，hash。
内存大小 = 键值个数 * (dictEntry 16byte + redisObject 16byte + 包含key的sds大小 + 包含value的sds大小) + bucket个数 * 4byte （bucket的大小是超过key个数向上求整的2的n次方）

###如何减少内存占用,[redis减少内存实战](https://www.qedev.com/bigdata/165762.html)
1. 使用短结构(int, ziplist, embstr)
2. 减少key的个数;
3. 使用bitmap位操作来减少内存占用



### 持久化问题
- 在没有开启持久化的情况下，redis宕机或者内存使用率超过95%会有丢数据的风险。
- 若使用快照(rdb)持久化，Redis会fork一个子进程把当前内存中的数据完全复制一份写入到硬盘上
  若是当前使用内存超过可用内存的45%时触发快照功能，那么此时进行的内存交换会变的非常危险(这个是错误的，有copy on write技术，不会有问题)

### [常见丢数据的情况](https://blog.csdn.net/u012322399/article/details/80743173)
-  1.网络分区的问题，可能导致短时间的写入数据丢失
     - 场景：集群产生脑裂之后，恢复时。
         某种原因(网络原因)集群出现了分区，master与slave节点之间断开了联系，
         1.sentinel监控到一段时间没有联系认为master故障，然后重新选举，将slave切换为新的master。
         2.但旧master可能并没有发生故障，只是网络产生分区，此时client任然在旧的master上写数据，而新的master中没有数据。
         3.如果不及时发现问题进行处理可能旧的master中堆积大量数据。
         4.在发现问题之后，旧的master降为slave同步新的master数据，那么之前的数据被刷新掉，大量数据丢失
     - 应对解决：
       1. 修改配置到合适值：min-slaves-to-write 1    min-slaves-max-lag 10
        配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求。
        因此在脑裂场景下，最多就丢失10秒的数据

-  2.主从复制数据不一致，发生故障切换后，出现数据丢失
      - 场景1：异步复制同步丢失  
       - master还没来得及同步给slave节点时发生宕机
       - 要是master中开启持久化设置数据可不可以保证不丢失呢？答案是否定的。
          在master 发生宕机后，sentinel集群检测到master发生故障，重新选举新的master，
          如果旧的master在故障恢复后重启，那么此时它需要同步新master的数据，
          此时新的master的数据是空的（假设这段时间中没有数据写入）。那么旧master中的数据就会被刷新掉，此时数据还是会丢失
    - 应对解决：
       1.修改配置到合适值：min-slaves-to-write 1    min-slaves-max-lag 10
         表示至少有1个salve的与master的同步复制延迟不能超过10s，一旦所有的slave复制和同步的延迟达到了10s，
         那么此时master就不会接受任何请求。
       2.对于client，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间后重新写入master来保证数据不丢失；
        也可以将数据写入kafka消息队列，隔一段时间去消费kafka中的数据
  - 场景2：正常的主从复制出现过期时间不一致问题
       1.master有expire命令，那么同步到slave中，该命令将会被延迟执行
       2.master在做RDB快照文件的时候，发现key已经过期了，则此时不会将过期的key写到RDB文件中
       3.slave在load RDB文件到内存中的时候，发现key已经过期了，则此时不会将过期的key load进去
    - 应对解决场景2：
       1.针对问题1，采用expireat timestamp 方式，这样命令传送到从库就没有影响。
       2.针对问题23，做数据校验的时候会有些影响，因为key不一致，但不影响业务逻辑
       3.如果想key数量一致，把上场景23都改为不忽略过期key，过期key的删除统一由主库触发删除，然后将删除命令传送到从库中。这样key的数量就完全一致了

-  3.内存使用过大，超过maxmemory，触发redis的数据淘汰机制，导致数据丢失(比如客户端缓冲区使用过大)
    - 场景：
      假设一个Redis设置了maxmemory为4G，已经存储了2G数据，但是如果此时输出缓冲区使用了3GB，
      已经超过了maxmemeory限制，可能会产生数据丢失，键值淘汰，OOM等情况。
    - 基础知识：
      1.每个client都有queryBuffer，outputBuffer
      2.client缓冲区的内存消耗计算在used_memory内.
      3.client-output-buffer-limit：可以设置三种不同client： normal，slave，pubsub；
      4.buffer-limit3个值： hard limit size / soft limit size / soft limit second;
          只要客户端使用output buffer内存大小超过hard limit限制，redis会立即关闭此客户端；
          使用buffer内存大小超过soft limit，并且持续soft limit秒数，redis也会立即关闭此客户端。
    - 应对解决：
      1.业务容量规划时把缓冲正常消耗计算在内，合理设置maxmemory的限制(最好可预留几百M)；
      2.对输出缓冲区设置合理limit；如normal设置10MB, SLAVE设置1GB等。 如果复制因slave线程输出缓冲区反复同步，需临时调大slave client-output-buffer，要同时调大maxmemory限制。
    - 运维监控
      1.通过采集client list输出，并分别统计求各所有客户端的(qbuf+ qbuf-free)和omem,但性能消耗大
      2.使用info的clients section中的client_biggest_input_buf和client_longest_output_list两个指标来监控告警
      3.监控键的LRU驱逐数量：evicted_keys
      4.监控内存使用大小 used_memory
    - tips
      1.监控redis used_memory如果抖动严重，极有可能就是输出缓冲区过大。
      2.增加slave的limit限制，避免slave同步线程被杀，导致无限循环同步数据；且slave线程和挂载的slave个数相同，理论只有几个
      3.禁止生产环境使用monitor命令，在高QPS环境下，monitor很快会产生output query使用

-  4.主库故障后自动重启，可能导致数据丢失
    - 场景：
      1.时间点T1,主库故障关闭了，因设置有自动重启的守护程序，时间点T2主库被重新拉起；
      2.因(T2-T1)时间间隔过小，未达到Redis集群或哨兵的主从切换判断时长；
      3.这样从库发现主库runid变了或断开过，会全量同步主库rdb清理，并清理自己的数据。
      4.为保障性能,Redis主库往往不做数据持久化设置，那么时间点T2启动的主库，很有可能是个空实例（或很久前的rdb文件）。
    - 解决
      1 反对Redis粗暴地设置自动重启
      2 这种监控键个数的变化，缓存命中率，同时ELK类型准实时监控redis日志变化并告警
-  5.程序bug或人为误操作：误删除数据； DBA/RD误操作执行flushall/flushdb这类命令      

       
### 大量过期键，同时被淘汰清理
- redis定期主动清理过期键，会导致Redis的键个数(dbsize)出现陡降(最大能达20%）。业务方常误以为有数据丢失。
    - 应对解决
       通过监控过期键淘汰的数量：expireed_keys的增长量，与dbsize键总数减少数据量是否相等。
    - 导致的一些奇怪现象：
       Master的键个数比Slave多20%； 高并发情况下，可能出现performance抖动,定期删除最坏可占25%的CPU时间片

### slave 与master发生连接断开，无限重连，无限同步问题
- client-output-buffer-limit slave 256mb 64mb 60
    这里对是客户端是slave的做限制，当output-buffer的大小大于256mb之后就会断开连接，大于64mb并且超过了60秒的时候就会断开连接
- repl-backlog-size(复制积压缓冲区是redis维护的固定长度环形缓冲队列)
* master的写入命令在同步给slaves的同时，会在缓冲区中写入一份(master只有1个积压缓冲区，所有slaves共享;
* 当redis复制中断后，slave会尝试采用psync, 上报原master runid + 当前已同步master的offset(复制偏移量，类似mysql的binlog file和position)；
* 如果runid与master的一致，且复制偏移量在master的复制积压缓冲区中还有(即offset >= min(backlog值)，master就认为部分重同步成功，不再进行全量同步，否则进行全量同步。


### 常见性能问题
1.rdb持久化，seve命令调度rdbsave函数，会阻塞主线程的工程，当快照比较大的时候对性能的影响是非常大的，会间断性暂停服务 。所以master最好不要写内存快照。
2.AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响master重启时的恢复速度。master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化，如果数据比较关键，某个slave开启AOF备份数据，策略每秒为同步一次。
3.调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂的服务暂停现象。
4.redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，slave和master最好在同一个局域网内