### 队列和消息队列有什么区别
1. 队列都是单机版， 持久化等也有问题，无法做到消息队列的特性；
2. 消息队列一般是服务之间的， 可以解耦、异步、削峰，水平扩展

###[MQ系列文章](https://blog.csdn.net/java_kider/category_10459877.html)

### 消息队列的通用优缺点：
优点：
解耦、异步、削峰，水平扩展
缺点有：
1.系统可用性降低，依赖mq组件的高可用
2.系统复杂度提高，比如数据一致性问题、证消息不被重复消费、保证消息可靠性传输、消息延时等

#### 几种mq 对比
- 1. 应用场景上的差异
    - RabbitMQ是一个消息代理，在它的设计理念里面，消息队列是一个管道;
    - Kafka是一个分布式流式系统，处理海量数据和实时计算;
- 2. 性能上
     2.1 吞吐量
       - kafka比rabbitmq吞吐量高一个数量级，如果要求高性能，不要选择rabbitmq
     2.2 伸缩性(分布式扩展能力)
       - rabbitmq 只需要简单的增删消费者就可以了
       - kafka在增加流量时，由于一个topic只能被消费组中的一个消费者消费，只能拓展topic的分区数量，增加更多消费者。
         在减少流量后，topic的分区不能向下减少(只能增加不能减少)
     2.3 消息积压
       - rabbitmq对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降
       - kafka没有积压这一说，使用文件存储；
     2.4 消息延时
       - rabbitmq的延时是微秒级，这是 RabbitMQ 的一大特点，延迟最低
       - rocketmq 在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。
       - kafka延时比较高，不太适合在线业务场景；
           设计上大量使用了批量和异步的思想，这种设计使得 Kafka 能做到超高的性能，但这种异步批量的设计带来的问题是，它的同步收发消息的响应时延比较高
           因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。
           当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合在线业务场景。
     2.5 多topic时的性能：

     2.6 稳定性


- 3. 消息处理方式上：
     3.1 路由方式
       - rabbitmq支持复杂路由
       - kafka只支持简单的topic路由
     3.2. 消息持久化(消息重放)
       - rabbitmq作为一个消息代理，消息处理完毕就删除不保留，同时queue里消息过多影响性能
       - kafka 可以设置保存时间，重复消费，消息数量的多少也不影响性能；
     3.3. 消息容错处理(消费失败)
       - rabbitmq 提供了死信队列，同时一个消息出问题不影响其他消费者；
       - kafka和rabbitmq都支持重试；同时当topic一个消息出问题时，顺序在后面的消息无法消费；
     3.4. 消息顺序性上的差异
       - rabbitmq 生产时无法保证顺序；在多消费者时无法保证顺行性；
       - kafka 保证单partition上的生产顺序；由消费者组保证每个topic只有一个消费者，是顺序的；
     3.5. 是否丢消息
       - rabbitmq 不丢消息
       - kafka，通过参数配置可以做到0丢消息

### 如何选型
看中的点是哪些？ 性能， 延时，还是什么；

1.协议：AMQP、STOMP、MQTT、私有协议等。
2.消息是否需要持久化。
3.吞吐量。
4.高可用支持，是否单点。
5.分布式扩展能力。
6.消息堆积能力和重放能力。
7.开发便捷，易于维护。
8.社区成熟度。
1.如果说，消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求，只需要一个开箱即用易于维护的产品，我建议你使用 RabbitMQ。
技术实力较为一般，技术挑战不是特别高
2.如果你的系统使用消息队列主要场景是处理在线业务，比如在交易系统中用消息队列传递订单，那 RocketMQ 的低延迟和金融级的稳定性是你需要的。
基础架构研发实力较强，用 RocketMQ 是很好的选择
3.如果你需要处理海量的消息，像收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品，那Kafka是最适合你的消息队列。


### kafka使用场景
1.消息处理-即传统MQ的功能
2.度量监控,数据指标
3.日志聚合
4.流式处理，实时计算

- rabbitmq的优缺点

- kafka的优点：
1. 高吞吐量、低延迟
2. 可扩展性：kafka集群支持热扩展
3. 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
4. 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
5. 高并发：支持数千个客户端同时读写
- kafka的缺点
1. 由于是批量发送，数据并非真正的实时；
2. 仅支持统一分区内消息有序，无法实现全局消息有序；
3. 监控不完善，需要安装插件；
4. 依赖zookeeper进行元数据管理；
5*. 对于mqtt协议不支持；
6*. 不支持物联网传感数据直接接入；

### MQ 的常见问题有：
1. 消息的顺序问题
  1. rabbitmq的顺序性
        1.producer保证发送消息的顺序性：
           1. channel内发送的消息是保证顺序性的， 自研确保channel与线程绑定。
           2. 继承AbstractRoutingConnectionFactory， 实现lookupkey方法，每个factory中只用一个channel。
        2.consumer端保证接受消息的顺序性
           1. 一个queue只用一个consumer消费(防止多消费者时，一个consumer消费失败，又传给别人消费)
  2. kafka消息的顺序性：
        1. 在同一个partition内有序方案一
             1.1. producer.send(record1, partition1)；之后producer.send(record2, partition1);
             1.2. Kafka配置了重试机制和max.in.flight.requests.per.connection大于1(默认值是5，本来就是大于1的)，
                    瞬时的网络抖动导致record1没有成功发送，record2发送成功了；那么重试record1后，record1就在record2之后了。
             1.3 如果要保证单partition内有序，需要设置max.in.flight.requests.per.connection=1.
        2. 在同一个partition内有序的方案二：
               使用幂等+重试：幂等保证record1没有成功前，record2会被broker抛弃； 重试机制保证了record2可以在record1成功后也成功。
        3. 在多个partition内无法保证有序

2. 重复消费消息问题
   - 使用幂等来处理
      1. 利用数据库的唯一约束实现幂等(插入)
      2. 为更新的数据设置前置条件(更新)
   
3. 如何保证不丢消息
   1. rabbitmq 如何保证不丢消息
      1. producer引入事务机制或者Confirm机制
          1. 同步发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失
          2. 异步发送时，则需要在回调方法里进行检查。(异步发送+回调通知+本地消息表+job轮询 方式解决)
      2. 消息队列进行消息持久化， 同时引入mirrored-queue镜像队列
          1. exchange持久化：channel.exchangeDeclare(exchangeName,"direct/topic/header/fanout",true);
          2. queue持久化：channel.queueDeclare(queueName,true,false,false,null);
          3. message持久化发送,设置BasicProperties的deliverayMode=2：
             (这样的话Rabbit会在消息提交到日志文件后才发送响应)
     3. consumer不自动ack，处理完成后再ack，
     4. 消息补偿机制，发送消息前入库，缺失消息后可以重发；
   2. kafka如何保证数据可靠性，不丢失消息
      1. 副本相关
            broker级别：关闭不完全的Leader选举，即 unclean.leader.election.enable=false；
                  (即不允许非ISR中的副本被选举为leader，以避免数据丢失)
            topic级别：设置 replication.factor>=3，并且 min.insync.replicas>=2；
      2. producer级别：
          1.acks=all（或者 request.required.acks=-1），
          2.发送模式为同步 producer.type=sync (异步时发送后先保存在缓冲区中，如果宕机则丢失全部消息)
          3.关闭自动提交：enable.auto.commit=false
          4.提交缓冲区满后一直阻塞不抛异常：block.on.buffer.full = true  尽管该参数在0.9.0.0已经被标记为“deprecated”，
             但鉴于它的含义非常直观，所以这里还是显式设置它为true，使得producer将一直等待缓冲区直至其变为可用。
             否则如果producer生产速度过快耗尽了缓冲区，producer将抛出异常。缓冲区满了就阻塞在那，不要抛异常，也不要丢失数据       

4. 保证数据的一致性
    1.kafka数据可靠性是由ISR中HW来控制的。
    
### 消息积压了该如何处理？
1. 日常系统正常运转的时候，没有积压或者只有少量积压很快就消费掉了
2. 某一个时刻，突然就开始积压消息并且积压持续上涨。这种情况下需要你在短时间内找到消息积压的原因，迅速解决问题才不至于影响业务。
3. 通过监控数据，定位是是发送变快了，还是消费变慢了。
     1.如果是单位时间发送的消息增多(抢购)，短时间内不太可能优化消费端的代码来提升消费性能，则通过扩容消费端的实例数来提升总体的消费能力。
     2.如果短时间内没有足够的服务器资源进行扩容，则将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。
4. 无论是发送消息的速度还是消费消息的速度和原来都没什么变化，检查消费日志
     1.没有日志错误的话，可以通过打印堆栈信息，看一下你的消费线程是不是卡在什么地方不动了，比如触发了死锁或者卡在等待某些资源上了。
     2.有大量消费失败的日志，这种情况也会拖慢整个系统的消费速度。
         大量消费失败，如果是bug
           1.紧急修复bug上线；
           2.如果时间来不及处理很麻烦，做转发处理，写一个临时的consumer消费方案，先把消息消费保存，然后再消费；
5. 上述问题处理不及时，导致大量消息堆积了几个小时的处理办法(百万消息等，目前线上处理不过来)  
    1. 目标：把积压的消息快速消费掉，不阻塞当前业务，积压的消息可以慢慢处理；
       解决：临时紧急扩容(需要考虑机器是否存在数据库竞争等情况，临时分发程序是否可以保证正确性，及时性)
         1.1 新建多个queue，将积压的消息轮询写入新建的多个queue中，进行快速消费；等消费完消息后，再去掉临时程序
         1.2 是否可以直接丢掉消息，后期找回？
6. 上述问题处理不及时，堆积的消息要过期了，或者消息积压达到磁盘上限，消息被删除了
    1. 目标：找回丢失消息
       解决： 通过各种方式找回
             1. producer发消息前要落库，之后进行重发；
             2. 通过其他方式，比如搜索mysql进行比对，找出需要发送的mq等，构建mq重发。

### kafka为什么这么快
- 1.顺序写磁盘
- 2.零拷贝技(消费者在读取数据时，数据拷贝两次才发送给消费者)
     在Linux kernel2.2 之后出现了一种叫做”零拷贝(zero-copy)”系统调用机制，就是跳过“用户缓冲区”的拷贝，
     建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”系统上下文切换减少为2次，可以提升一倍的性能
- 3.文件分段， 建立索引
- 4.批量发送
- 5.支持消息集合进行压缩。

- 2.大量使用内存页(这个怎么理解记忆？)
   - 利用(Memory-Mapped-Files,mmap技术)
       直接利用操作系统的Page来实现磁盘文件到物理内存的直接映射
       写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。
   - producer.type 参数控制是不是主动flush
       同步(sync): Kafka写入到mmap之后就立即flush然后再返回Producer
       异步(async,默认):写入mmap之后立即返回Producer不调用flush
