### 第一步
 使用nginx/lvs进行前端负载均衡，使得流量均分到后台机器上

### 流量
0. 前端限流，通过令牌桶算法等技术限制单位时间内提交到服务器的请求量，降低qps。
1. 服务端引入异步处理机制，比如mq队列，进行削峰填谷。

### 高并发核心- 订单与库存
1.下单同时预占库存
2.支付
3.支付成功真正减扣库存
4.取消订单,回退预占库存

- 如何安全的扣减库存?
1.使用了数据库的乐观锁来控制库存安全更新库存的语句，在并发量不是很大的情况下可以这么做。
  但是如果是秒杀，瞬时流量很高的话，压力会都到数据库，可能拖垮数据库。
   具体操作：增加availableNum>0, availableNum - num >= 0； 这个类似版本号
2.使用分布式锁(强制把处理请求串行化)； 缺点是并发不高，用户体验不好.
3.利用Redis increment的原子操作 + 乐观锁；(事前把库存load到redis中，先扣减redis数量，再更新库)
4.db性能扛不住时降级为写扣减DB库存消息到本机，然后本机通过异步进行DB库存扣减，


### 100万的qps 抢1万个秒杀商品； (单机redis10万的并发量，扛不住100万的qps请求)
1. 使用100台机器，每台机器抗1万的qps;
2. 每台机器分110个秒杀商品；(如果每台机器是100个商品，那么有机器宕机时就无法卖出的风险，需要使用buffer)；
3. 使用两级缓存方案，
    一级缓存(redis/本机缓存): 和机器相关，存放110个商品；
    二级缓存redis：和秒杀总数相关：1万个商品；
4. 当秒杀请求进来时：(一级缓存+二级缓存进行库存扣件)
    1. 判断一级缓存是否有库存，如果没有直接返回失败；
    2. 如果一级缓存有库存，继续去二级缓存查看，如果二级缓存也有库存，则进行扣件，返回秒杀成功;
5. 此时如此大的并发量，数据库依然扛不住，可以改为使用队列；(下单链路长，需要进行各种校验，所以使用队列，只有有库存，就先放到队列中)
    只要有秒杀成功，就将订单放到队列中，然后慢慢的进行mysql落库；

*** 这样为什么能扛住100万的qps呢
    因为100万的qps进来后，只有在一级缓存通过后才会打请求到二级缓存上，这样二级缓存的并发qps不会超过秒杀商品总量；